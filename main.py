import os 
import cv2
import csv
import numpy as np
import pandas as pd
import joblib
from tqdm import tqdm
from sklearn.metrics import accuracy_score,confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
# Giáº£ sá»­ cÃ¡c module nÃ y báº¡n Ä‘Ã£ viáº¿t chuáº©n
from src.data import download_datasets
from src.features import extract_landmarks
from src.model.train import train_model
import random # ThÃªm thÆ° viá»‡n random cho Augmentation
from joblib import Parallel, delayed # ThÃªm xá»­ lÃ½ Ä‘a luá»“ng

def get_column_names():
    cols = ['Label']
    
    expert_cols = [
        'thumb_depth', 'dist_thumb_mid', 'thumb_offset_x', 'thumb_ratio',
        'cross_direction_x', 'ext_ring_finger', 'dist_thumb_mid_pip', 'curl_idx',
        'mn_diff', 'finger_orientation', 'pinky_curl',
        'd_tip', 'gap_y'  
    ]
    cols.extend(expert_cols)
    
    for i in range(21):
        cols.extend([f'x{i}', f'y{i}', f'z{i}'])
        
    for i in range(324):
        cols.append(f'hog_{i}')
        
    return cols
def augment_image(image):
    """
    Thá»±c hiá»‡n Data Augmentation (TÄƒng cÆ°á»ng dá»¯ liá»‡u) Ä‘Æ¡n giáº£n báº±ng OpenCV.
    Tráº£ vá» danh sÃ¡ch cÃ¡c áº£nh Ä‘Ã£ Ä‘Æ°á»£c biáº¿n Ä‘á»•i (Bao gá»“m áº£nh gá»‘c).
    """
    aug_images = [image]
    
    # 1. Láº­t áº£nh ngang (Flip Horizontal) - Biáº¿n tay pháº£i thÃ nh tay trÃ¡i
    # LÆ¯U Ã: Ráº¥t cáº©n tháº­n vá»›i táº­p Sign Language! Má»™t sá»‘ chá»¯ láº­t ngang sáº½ máº¥t Ã½ nghÄ©a.
    # Trong ASL, Ä‘a sá»‘ chá»¯ cÃ¡i dÃ¹ng 1 tay thÃ¬ láº­t ngang váº«n xÃ i Ä‘Æ°á»£c (nhÆ° J thÃ¬ láº­t sáº½ thÃ nh ngÆ°á»£c).
    # Ta chá»‰ thÃªm Ä‘á»™ sÃ¡ng, Ä‘á»™ tÆ°Æ¡ng pháº£n Ä‘á»ƒ giá»¯ cáº¥u trÃºc chá»¯ nguyÃªn váº¹n nháº¥t!
    
    # 2. Thay Ä‘á»•i Ä‘á»™ sÃ¡ng ngáº«u nhiÃªn (Brightness)
    value = random.randint(-40, 40)
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    v = cv2.add(v, value)
    v[v > 255] = 255
    v[v < 0] = 0
    final_hsv = cv2.merge((h, s, v))
    img_brightness = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)
    aug_images.append(img_brightness)
    
    # 3. PhÃ³ng to nháº¹ (Zoom In - Scale) Ä‘á»ƒ mÃ´ phá»ng Ä‘Æ°a tay láº¡i gáº§n
    height, width = image.shape[:2]
    scale = random.uniform(1.05, 1.2)
    center_x, center_y = width / 2, height / 2
    M = cv2.getRotationMatrix2D((center_x, center_y), 0, scale)
    img_zoomed = cv2.warpAffine(image, M, (width, height))
    aug_images.append(img_zoomed)
    
    return aug_images

def process_single_image(image_path, label):
    """
    HÃ m xá»­ lÃ½ cho 1 áº£nh Ä‘Æ¡n láº» Ä‘á»ƒ cháº¡y Ä‘a luá»“ng.
    Äá»c áº£nh, Augment, vÃ  TrÃ­ch xuáº¥t Äáº·c trÆ°ng.
    Tráº£ vá» list cÃ¡c rows (dÃ²ng data) há»£p lá»‡.
    """
    rows = []
    img = cv2.imread(image_path)
    if img is None: return rows
    
    augmented_imgs = augment_image(img)
    for aug_img in augmented_imgs:
        features = extract_landmarks(aug_img)
        if features is not None:
            rows.append([label] + features)
    return rows

def extract_training_features():
    data_dir = 'Datasets/raw/asl_alphabet_train'
    
    # KAGGE FIX: Kaggle giáº£i nÃ©n thÆ° má»¥c bá»‹ lá»“ng vÃ o trong (VÃ­ dá»¥: asl_alphabet_train/asl_alphabet_train/A)
    # Ta pháº£i chui vÃ o thÃªm 1 lá»›p náº¿u thÆ° má»¥c Ä‘Ã³ xuáº¥t hiá»‡n
    if os.path.exists(os.path.join(data_dir, 'asl_alphabet_train')):
        data_dir = os.path.join(data_dir, 'asl_alphabet_train')
        
    output_dir = 'Datasets/preprocessing/train_features.csv'
    
    # CASH MEMORY: Khá»i cháº¡y láº¡i ná»­a tiáº¿ng náº¿u Ä‘Ã£ cÃ³ sáºµn
    if os.path.exists(output_dir):
        print(f"ðŸ‘‰ [Bá»Ž QUA] ÄÃ£ tÃ¬m tháº¥y tá»‡p {output_dir}. Nháº£y qua bÆ°á»›c TrÃ­ch xuáº¥t Features Train!")
        return
        
    os.makedirs(os.path.dirname(output_dir), exist_ok=True)
    cols = get_column_names()

    # Thu tháº­p toÃ n bá»™ Ä‘Æ°á»ng dáº«n áº£nh vÃ  nhÃ£n
    image_tasks = []
    if os.path.exists(data_dir):
        labels = os.listdir(data_dir)
        for label in labels:
            label_path = os.path.join(data_dir, label)
            if not os.path.isdir(label_path): continue
            
            for image_name in os.listdir(label_path):
                image_tasks.append((os.path.join(label_path, image_name), label))
                
    if not image_tasks:
        print("[THÃ”NG BÃO] KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u Train. Bá» qua bÆ°á»›c Extract.")
        return

    print(f"Äang chuáº©n bá»‹ trÃ­ch xuáº¥t {len(image_tasks)} file áº£nh gá»‘c (Sáº½ x3 nhá» Augmentation)...")
    
    # Cáº¤U HÃŒNH Tá»I Æ¯U CHO Intel i5-14600KF (20 threads)
    # DÃ¹ng 12 luá»“ng Ä‘á»ƒ cÃ¢n báº±ng tá»‘c Ä‘á»™ siÃªu nhanh vÃ  tÃ­nh á»•n Ä‘á»‹nh cá»§a Windows OS
    results = Parallel(n_jobs=12, batch_size=10)(
        delayed(process_single_image)(img_path, lbl) 
        for img_path, lbl in tqdm(image_tasks, desc="Extracting (Multi-core)")
    )
    
    # Gá»™p káº¿t quáº£ vÃ  Ghi ra file CSV
    total_images = 0
    with open(output_dir, mode='w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(cols)
        
        for row_list in results:
            for row in row_list:
                writer.writerow(row)
                total_images += 1

    print(f"COMPLETED! EXTRACT TRAINING FEATURES {total_images} rows")
    print(f"Data saved: {output_dir}")
    
def extract_testing_features():
    test_dir = 'Datasets/raw/test_datasets/new_test'
    test_dir2 = 'Datasets/raw/asl_alphabet_test'
    
    # TÆ°Æ¡ng tá»± nhÆ° táº­p Train, náº¿u Kaggle giáº£i nÃ©n bá»‹ lá»“ng 2 thÆ° má»¥c
    if os.path.exists(os.path.join(test_dir2, 'asl_alphabet_test')):
        test_dir2 = os.path.join(test_dir2, 'asl_alphabet_test')
        
    output_dir = 'Datasets/preprocessing/test_features.csv'
    
    # CASH MEMORY 
    if os.path.exists(output_dir):
        print(f"ðŸ‘‰ [Bá»Ž QUA] ÄÃ£ tÃ¬m tháº¥y tá»‡p {output_dir}. Nháº£y qua bÆ°á»›c TrÃ­ch xuáº¥t Features Test!")
        return

    os.makedirs(os.path.dirname(output_dir), exist_ok=True)
    cols = get_column_names()
    
    with open(output_dir, mode='w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(cols)
        total_images = 0

        # --- Xá»­ lÃ½ test_dir ---
        if os.path.exists(test_dir):
            labels = os.listdir(test_dir)
            for label in labels:
                label_path = os.path.join(test_dir, label)
                if not os.path.isdir(label_path): 
                    continue

                for image_name in tqdm(os.listdir(label_path), desc=f'Extracting {label} (test_dir)'):
                    image_path = os.path.join(label_path, image_name)
                    features = extract_landmarks(image_path)

                    if features is not None:
                        row = [label] + features
                        writer.writerow(row)
                        total_images += 1

        # --- Xá»­ lÃ½ test_dir2 ---
        if os.path.exists(test_dir2):
            for image_name in tqdm(os.listdir(test_dir2), desc='Extracting test data (test_dir2)'):
                image_path = os.path.join(test_dir2, image_name)
                features = extract_landmarks(image_path)

                if features is not None:
                    real_label = image_name.split('_')[0] 
                    row = [real_label] + features
                    writer.writerow(row)
                    total_images += 1

        print("------------------------------------------------")

    print(f"COMPLETED! EXTRACT TESTING FEATURES {total_images} images")
    print(f"Data saved: {output_dir}")
    


def implement_model():
    model_dir = 'model_saved/moe_hybrid_clf.pkl'
    test_csv = 'Datasets/preprocessing/test_features.csv'
    
    if not os.path.exists(model_dir):
        print(f"Lá»–I: KhÃ´ng tÃ¬m tháº¥y mÃ´ hÃ¬nh táº¡i {model_dir}")
        return
    
    print(f"--- Äang táº£i mÃ´ hÃ¬nh tá»« {model_dir} ---")
    artifacts = joblib.load(model_dir)
    
    model_general = artifacts['model_general']
    experts = artifacts['experts']
    expert_configs = artifacts.get('expert_configs') 
    le = artifacts['label_encoder']
    
    if expert_configs is None:
        print("Lá»–I: File model thiáº¿u key 'expert_configs'. HÃ£y kiá»ƒm tra láº¡i file train.py!")
        return

    df_test = pd.read_csv(test_csv).dropna(subset=['Label'])
    
    # GUARD: Náº¿u test CSV rá»—ng thÃ¬ bá» qua
    if len(df_test) == 0:
        print("[Cáº¢NH BÃO] Test CSV rá»—ng. Bá» qua implement_model.")
        return
    
    X_test = df_test.drop('Label', axis=1)
    # Báº®T BUá»˜C: Ã‰p kiá»ƒu toÃ n bá»™ X vá» float32 (trÃ¡nh lá»—i 'object' dtype)
    X_test = X_test.apply(pd.to_numeric, errors='coerce').fillna(0).astype('float32')
    y_test_raw = df_test['Label'].astype(str)
    y_test_encoded = le.transform(y_test_raw)
    
    print("--- Táº§ng 1: XGBoost Ä‘ang xá»­ lÃ½ tá»•ng quÃ¡t ---")
    y_pred_general = model_general.predict(X_test)
    y_pred_final = y_pred_general.copy()
    
    print("--- Táº§ng 2: SVM Ä‘ang kiá»ƒm tra chÃ©o cÃ¡c cá»¥m nháº¡y cáº£m ---")
    
    for i in range(len(y_pred_general)):
        xgb_idx = y_pred_general[i]
        xgb_label = le.inverse_transform([xgb_idx])[0]
        
        target_expert_name = None
        for exp_name, config in expert_configs.items():
            if xgb_label in config['classes']:
                target_expert_name = exp_name
                break
        
        if target_expert_name and target_expert_name in experts:
            expert_model = experts[target_expert_name]
            weapons = expert_configs[target_expert_name]['weapons']
            
            # Chá»‰ trÃ­ch xuáº¥t Ä‘Ãºng cÃ¡c cá»™t "vÅ© khÃ­" mÃ  chuyÃªn gia nÃ y cáº§n
            row_features = X_test.iloc[[i]][weapons] 
            
            # SVM ra quyáº¿t Ä‘á»‹nh cuá»‘i cÃ¹ng
            svm_decision = expert_model.predict(row_features)[0]
            # Cáº­p nháº­t láº¡i káº¿t quáº£ vÃ o máº£ng dá»± Ä‘oÃ¡n cuá»‘i cÃ¹ng
            y_pred_final[i] = le.transform([svm_decision])[0]

    # 6. ÄÃ¡nh giÃ¡ vÃ  bÃ¡o cÃ¡o
    acc = accuracy_score(y_test_encoded, y_pred_final)
    print(f"\n[Káº¾T QUáº¢] Accuracy MoE Hybrid: {acc:.4f}")
    

    # 7. Váº½ Confusion Matrix (Chuáº©n 29 lá»›p)
    cm = confusion_matrix(y_test_encoded, y_pred_final, labels=range(len(le.classes_)))
    plt.figure(figsize=(22, 18))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', 
                xticklabels=le.classes_,
                yticklabels=le.classes_)
    
    plt.xlabel('Dá»± Ä‘oÃ¡n (Predicted)')
    plt.ylabel('Thá»±c táº¿ (True)')
    plt.title('Confusion Matrix - Mixture of Experts (MoE) Final System')
    plt.show()
def main():
    # ============================================================
    # CÃ€I Äáº¶T NHANH: Äáº·t True/False Ä‘á»ƒ báº­t/táº¯t tá»«ng bÆ°á»›c
    # ============================================================
    SKIP_DOWNLOAD = False   # True = Bá» qua bÆ°á»›c táº£i Data tá»« Kaggle
    SKIP_EXTRACT  = False   # True = Bá» qua bÆ°á»›c trÃ­ch xuáº¥t features (dÃ¹ng láº¡i CSV cÅ©)
    SKIP_TRAIN    = False   # True = Bá» qua bÆ°á»›c Train (dÃ¹ng láº¡i Model cÅ©)
    # ============================================================

    if not SKIP_DOWNLOAD:
        download_datasets()
    else:
        print("[Bá»Ž QUA] BÆ°á»›c táº£i Data (SKIP_DOWNLOAD = True)")
    
    if not SKIP_EXTRACT:
        extract_training_features()
        extract_testing_features()
    else:
        print("[Bá»Ž QUA] BÆ°á»›c trÃ­ch xuáº¥t Features (SKIP_EXTRACT = True)")
    
    if not SKIP_TRAIN:
        train_model()
        implement_model()
    else:
        print("[Bá»Ž QUA] BÆ°á»›c Train Model (SKIP_TRAIN = True)")

if __name__ == "__main__":
    main()